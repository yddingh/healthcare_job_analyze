{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5228ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from html import unescape\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "raw_path = r\"C:\\Users\\JKK4V3PX\\healthcare_job_analyze\\healthcare_job\\data\\emed_careers_eu.csv\"\n",
    "df = pd.read_csv(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769f52f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns: (39774, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clinical Research</td>\n",
       "      <td>PPD GLOBAL LTD</td>\n",
       "      <td>As part of our on-going growth, we are current...</td>\n",
       "      <td>Senior / Medical Writer (Regulatory)</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>4/14/2018</td>\n",
       "      <td>Competitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Science</td>\n",
       "      <td>AL Solutions</td>\n",
       "      <td>Manager of Biometrics – Italy\\nAL Solutions ar...</td>\n",
       "      <td>Manager of Biometrics</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Europe</td>\n",
       "      <td>4/16/2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Science</td>\n",
       "      <td>Seltek Consultants Ltd</td>\n",
       "      <td>A fantastic opportunity has arisen for an expe...</td>\n",
       "      <td>Field Service Engineer | Chromatography</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>UK</td>\n",
       "      <td>4/16/2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Management and Statistics</td>\n",
       "      <td>Docs International UK Limited</td>\n",
       "      <td>Job Details\\n:\\nUtilise extensive clinical dat...</td>\n",
       "      <td>Data Manager of Project Management</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>M4 Corridor</td>\n",
       "      <td>4/11/2018</td>\n",
       "      <td>On Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Hyper Recruitment Solutions Ltd</td>\n",
       "      <td>Hyper Recruitment Solutions are currently look...</td>\n",
       "      <td>Strategic Market Analyst</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>4/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category                      company_name  \\\n",
       "0               Clinical Research                    PPD GLOBAL LTD   \n",
       "1                         Science                      AL Solutions   \n",
       "2                         Science            Seltek Consultants Ltd   \n",
       "3  Data Management and Statistics     Docs International UK Limited   \n",
       "4                         Science   Hyper Recruitment Solutions Ltd   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  As part of our on-going growth, we are current...   \n",
       "1  Manager of Biometrics – Italy\\nAL Solutions ar...   \n",
       "2  A fantastic opportunity has arisen for an expe...   \n",
       "3  Job Details\\n:\\nUtilise extensive clinical dat...   \n",
       "4  Hyper Recruitment Solutions are currently look...   \n",
       "\n",
       "                                 job_title   job_type     location  post_date  \\\n",
       "0     Senior / Medical Writer (Regulatory)  Permanent    Cambridge  4/14/2018   \n",
       "1                   Manager of Biometrics   Permanent       Europe  4/16/2018   \n",
       "2  Field Service Engineer | Chromatography  Permanent           UK  4/16/2018   \n",
       "3       Data Manager of Project Management  Permanent  M4 Corridor  4/11/2018   \n",
       "4                 Strategic Market Analyst  Permanent    Cambridge  4/13/2018   \n",
       "\n",
       "   salary_offered  \n",
       "0     Competitive  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3  On Application  \n",
       "4             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39774 entries, 0 to 39773\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   category         30000 non-null  object\n",
      " 1   company_name     30000 non-null  object\n",
      " 2   job_description  30000 non-null  object\n",
      " 3   job_title        30000 non-null  object\n",
      " 4   job_type         30000 non-null  object\n",
      " 5   location         30000 non-null  object\n",
      " 6   post_date        30000 non-null  object\n",
      " 7   salary_offered   22685 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "\n",
      "--- Missing per column ---\n",
      "salary_offered     17089\n",
      "category            9774\n",
      "job_description     9774\n",
      "company_name        9774\n",
      "job_title           9774\n",
      "job_type            9774\n",
      "location            9774\n",
      "post_date           9774\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows, Columns:\", df.shape)\n",
    "display(df.head(5))\n",
    "print(\"--- Info ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Missing per column ---\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d428c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 定义若干辅助函数，用于后续清理数据\n",
    "\n",
    "# define keywords for searching\n",
    "SKILL_KEYWORDS = [\n",
    "    \"python\",\"sql\",\"sas\",\"r\",\"cdisc\",\"adverse\",\"pharmacovigilance\",\"spss\",\n",
    "    \"machine learning\",\"data analysis\",\"biostatistics\",\"clinical\",\"gcp\",\"cdash\"\n",
    "]\n",
    "\n",
    "# 清理字符串的前后空格,并把空/NaN标准化为 None\n",
    "def safe_strip(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x)\n",
    "    s = s.strip()\n",
    "    return s if s != \"\" else None\n",
    "\n",
    "\n",
    "# 日期转换\n",
    "def parse_date(s):\n",
    "    try:\n",
    "        return pd.to_datetime(s, errors='coerce', dayfirst=True)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "\n",
    "# 把location拆分成地区和国家\n",
    "def parse_location(loc):\n",
    "    # 依据逗号或竖线或短横拆分：最后一段通常为country\n",
    "    if pd.isna(loc):\n",
    "        return (None, None)\n",
    "    s = str(loc).strip()\n",
    "    parts = [p.strip() for p in re.split(r',|\\||-', s) if p.strip()]\n",
    "    if len(parts) == 0:\n",
    "        return (None, None)\n",
    "    if len(parts) == 1:\n",
    "        # 只有一个字段：可能是 \"Europe\" 或 \"UK\" 或 \"Cambridge\"\n",
    "        # 简单规则：若单词长度<=3并全大写，可能是国家缩写 -> 视为 country 否则 city\n",
    "        token = parts[0]\n",
    "        if token.isupper() and len(token) <= 3:\n",
    "            return (None, token)\n",
    "        # 若是常见 continent/country词\n",
    "        if token.lower() in [\"europe\",\"uk\",\"usa\",\"us\",\"UK\",\"germany\",\"france\"]:\n",
    "            return (None, token)\n",
    "        return (token, None)\n",
    "    # 多段：最后一段当作 country，其余合并为 city\n",
    "    city = \", \".join(parts[:-1])\n",
    "    country = parts[-1]\n",
    "    return (city if city else None, country if country else None)\n",
    "\n",
    "#拆分薪资\n",
    "def parse_salary(text):\n",
    "    # 返回 (min, max, currency, parsed_flag)\n",
    "    if pd.isna(text):\n",
    "        return (None, None, None, False)\n",
    "    s = str(text).strip()\n",
    "    s_lower = s.lower()\n",
    "    # 常见非结构化文本，判断特殊词\n",
    "    if any(term in s_lower for term in [\"competitive\",\"on application\",\"negotiable\",\"not disclosed\",\"tbd\"]):\n",
    "        return (None, None, None, False)\n",
    "    # 找货币符号或货币文本\n",
    "    cur = None\n",
    "    cur_search = re.search(r'€|£|\\$|usd|eur|gbp', s, flags=re.IGNORECASE)\n",
    "    if cur_search:\n",
    "        cur = cur_search.group(0)\n",
    "    # 提取所有数字串（忽略小数点分隔）\n",
    "    nums = re.findall(r'\\d{3,}', s.replace(',', ''))\n",
    "    if len(nums) == 0:\n",
    "        # 尝试找较短数字如 50k, 45k\n",
    "        k_match = re.findall(r'(\\d{2,3})k', s_lower)\n",
    "        if k_match:\n",
    "            val = int(k_match[0]) * 1000\n",
    "            return (val, val, cur, True)\n",
    "        return (None, None, cur, False)\n",
    "    if len(nums) == 1:\n",
    "        v = int(nums[0])\n",
    "        return (v, v, cur, True)\n",
    "    # 2个以上，取前两个为区间\n",
    "    vmin = int(nums[0])\n",
    "    vmax = int(nums[1])\n",
    "    if vmin > vmax:\n",
    "        vmin, vmax = vmax, vmin\n",
    "    return (vmin, vmax, cur, True)\n",
    "\n",
    "\n",
    "# 去除 HTML 标签、转义符，归一化空白，返回清洁的描述字符串。避免描述里有换行或 HTML 导致展示/统计问题。\n",
    "def clean_description(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    t = unescape(str(text))\n",
    "    # 去掉HTML标签\n",
    "    t = re.sub(r'<[^>]+>', ' ', t)\n",
    "    # 转换连续空白为单空格\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "#把描述转小写，检查关键词列表，生成一个简单的技能标签，用于后续筛选或可视化\n",
    "def extract_skill_flags(text):\n",
    "    t = (text or \"\").lower()\n",
    "    found = [kw for kw in SKILL_KEYWORDS if kw in t]\n",
    "    return \",\".join(found) if found else None\n",
    "\n",
    "\n",
    "# 生成job id\n",
    "def make_job_id(row):\n",
    "    # 用 company+title+date 做hash，确保稳定\n",
    "    key = f\"{row.get('company_name','') or ''}|{row.get('job_title','') or ''}|{row.get('post_date_parsed_str','') or ''}\"\n",
    "    return hashlib.md5(key.encode('utf-8')).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad0a97c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed exact duplicates: 23022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKK4V3PX\\AppData\\Local\\Temp\\ipykernel_25676\\2318282742.py:21: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicates by job_id: 13108\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 实际清洗\n",
    "\n",
    "# 1. 复制一份操作，保留原始 df\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 2. 统一缺失值格式并消除无意义的空格\n",
    "for c in ['category','company_name','job_description','job_title','job_type','location','post_date','salary_offered']:\n",
    "    if c in df_clean.columns:\n",
    "        df_clean[c] = df_clean[c].apply(safe_strip)\n",
    "\n",
    "# 3. 去重\n",
    "before = df_clean.shape[0]\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "after = df_clean.shape[0]\n",
    "print(f\"Removed exact duplicates: {before - after}\")\n",
    "\n",
    "# 4. 解析日期\n",
    "if 'post_date' in df_clean.columns:\n",
    "    df_clean['post_date_parsed'] = df_clean['post_date'].apply(parse_date)\n",
    "    # 也保留一个字符串格式（便于做id）\n",
    "    df_clean['post_date_parsed_str'] = df_clean['post_date_parsed'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 5. 解析location\n",
    "if 'location' in df_clean.columns:\n",
    "    loc_parsed = df_clean['location'].apply(parse_location)\n",
    "    df_clean['city'] = loc_parsed.apply(lambda x: x[0])\n",
    "    df_clean['country'] = loc_parsed.apply(lambda x: x[1])\n",
    "\n",
    "# 6. 标准化job_type\n",
    "def norm_job_type(s):\n",
    "    if not s: return \"Unknown\"\n",
    "    s = s.lower()\n",
    "    if 'perm' in s: return 'Permanent'\n",
    "    if 'contract' in s: return 'Contract'\n",
    "    if 'temp' in s or 'temporary' in s: return 'Temporary'\n",
    "    if 'intern' in s or 'graduate' in s: return 'Internship'\n",
    "    return 'Other'\n",
    "if 'job_type' in df_clean.columns:\n",
    "    df_clean['job_type_std'] = df_clean['job_type'].apply(norm_job_type)\n",
    "\n",
    "# 7. 清理job_description\n",
    "if 'job_description' in df_clean.columns:\n",
    "    df_clean['job_description_clean'] = df_clean['job_description'].apply(clean_description)\n",
    "    df_clean['desc_word_count'] = df_clean['job_description_clean'].apply(lambda t: len(t.split()) if t else 0)\n",
    "    df_clean['skill_flags'] = df_clean['job_description_clean'].apply(extract_skill_flags)\n",
    "\n",
    "# 8. 解析salary\n",
    "if 'salary_offered' in df_clean.columns:\n",
    "    sal_parsed = df_clean['salary_offered'].apply(parse_salary)\n",
    "    df_clean['salary_min'] = sal_parsed.apply(lambda x: x[0])\n",
    "    df_clean['salary_max'] = sal_parsed.apply(lambda x: x[1])\n",
    "    df_clean['salary_currency'] = sal_parsed.apply(lambda x: x[2])\n",
    "    df_clean['salary_parsed'] = sal_parsed.apply(lambda x: x[3])\n",
    "\n",
    "# 9. 生成 job_id 并根据 job_id 去重\n",
    "df_clean['job_id'] = df_clean.apply(make_job_id, axis=1)\n",
    "before = df_clean.shape[0]\n",
    "df_clean = df_clean.drop_duplicates(subset=['job_id'])\n",
    "after = df_clean.shape[0]\n",
    "print(f\"Removed duplicates by job_id: {before - after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f784db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[['job_id',\n",
    "                     'post_date_parsed',\n",
    "                     'category',\n",
    "                     'job_type_std', \n",
    "                     'job_title',                                         \n",
    "                     'job_description_clean',\n",
    "                     'desc_word_count',                    \n",
    "                     'skill_flags',\n",
    "                   \n",
    "                     'company_name',\n",
    "                     'city',\n",
    "                     'country',\n",
    "\n",
    "                     'salary_offered',\n",
    "                     'salary_min',\n",
    "                     'salary_max',\n",
    "                     'salary_currency',\n",
    "                     'salary_parsed'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebef6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_labels = ['France', 'Germany', 'Italy', 'Spain', 'Switzerland', 'UK']\n",
    "df_clean['category'] = df_clean['category'].replace({'science': 'Science'})\n",
    "df_clean.loc[df_clean['category'].isin(country_labels), 'category'] = None\n",
    "\n",
    "city_to_country = {\n",
    "    \"Basel\": \"Switzerland\",\n",
    "    \"Birmingham\": \"UK\",\n",
    "    \"Cambridge\": \"UK\",\n",
    "    \"cambridge\": \"UK\",\n",
    "    \"Italy\": \"Italy\",\n",
    "    \"italy\": \"Italy\",\n",
    "    \"London\": \"UK\",\n",
    "    \"M4 Corridor\": \"UK\",\n",
    "    \"Manchester\": \"UK\",\n",
    "    \"North West\": \"UK\",\n",
    "    \"Oxford\": \"UK\",\n",
    "    \"Paris\": \"France\",\n",
    "    \"Scotland\": \"UK\",\n",
    "    \"South East\": \"UK\",\n",
    "    \"Spain\": \"Spain\",\n",
    "    \"spain\": \"Spain\",\n",
    "    \"Switzerland\": \"Switzerland\",\n",
    "    \"switzerland\": \"Switzerland\",\n",
    "}\n",
    "df_clean['country'] = df_clean['country'].fillna(df_clean['city'].map(city_to_country))\n",
    "\n",
    "country_standard_map = {\n",
    "    \"France\": \"France\",\n",
    "    \"france\": \"France\",\n",
    "    \"Germany\": \"Germany\",\n",
    "    \"germany\": \"Germany\",\n",
    "    \"UK\": \"UK\",\n",
    "    \"uk\": \"UK\",\n",
    "    \"Europe\": \"Europe\",  \n",
    "}\n",
    "df_clean['country'] = df_clean['country'].map(country_standard_map).fillna(df_clean['country'])\n",
    "\n",
    "currency_map = {\n",
    "    \"$\": \"USD\",\n",
    "    \"EUR\": \"EUR\",\n",
    "    \"Eur\": \"EUR\",\n",
    "    \"€\": \"EUR\",\n",
    "    \"£\": \"GBP\"\n",
    "}\n",
    "df_clean['salary_currency'] = df_clean['salary_currency'].map(currency_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72223cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----isnull------\n",
      "job_id                      0\n",
      "post_date_parsed            1\n",
      "category                   56\n",
      "job_type_std                0\n",
      "job_title                   1\n",
      "job_description_clean       0\n",
      "desc_word_count             0\n",
      "skill_flags                 1\n",
      "company_name                1\n",
      "city                     2055\n",
      "country                     1\n",
      "salary_offered            859\n",
      "salary_min               3089\n",
      "salary_max               3089\n",
      "salary_currency          3349\n",
      "salary_parsed               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-----isnull------\")\n",
    "print(df_clean.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44bca23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----unique------\n",
      "job_id                   3644\n",
      "post_date_parsed           15\n",
      "category                   11\n",
      "job_type_std                5\n",
      "job_title                1895\n",
      "job_description_clean    2910\n",
      "desc_word_count           604\n",
      "skill_flags                66\n",
      "company_name              164\n",
      "city                       18\n",
      "country                     7\n",
      "salary_offered            669\n",
      "salary_min                 72\n",
      "salary_max                 80\n",
      "salary_currency             3\n",
      "salary_parsed               2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-----unique------\")\n",
    "print(df_clean.nunique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25820cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>post_date_parsed</th>\n",
       "      <th>category</th>\n",
       "      <th>job_type_std</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description_clean</th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>skill_flags</th>\n",
       "      <th>company_name</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15cc819a5d9a4b298bcc5fd839bd65a3</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>Clinical Research</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Senior / Medical Writer (Regulatory)</td>\n",
       "      <td>As part of our on-going growth, we are current...</td>\n",
       "      <td>359</td>\n",
       "      <td>r,biostatistics,clinical</td>\n",
       "      <td>PPD GLOBAL LTD</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>UK</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31c1a5eac509952eeb8cfdccbeb2fcc4</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>Science</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Manager of Biometrics</td>\n",
       "      <td>Manager of Biometrics – Italy AL Solutions are...</td>\n",
       "      <td>291</td>\n",
       "      <td>sas,r,clinical</td>\n",
       "      <td>AL Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>Europe</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7b6abf608611f7c6b97be78b5914d26c</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>Science</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Field Service Engineer | Chromatography</td>\n",
       "      <td>A fantastic opportunity has arisen for an expe...</td>\n",
       "      <td>374</td>\n",
       "      <td>r</td>\n",
       "      <td>Seltek Consultants Ltd</td>\n",
       "      <td>None</td>\n",
       "      <td>UK</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63542ffb0393034e35a3f9753b274b73</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Data Management and Statistics</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Data Manager of Project Management</td>\n",
       "      <td>Job Details : Utilise extensive clinical data ...</td>\n",
       "      <td>279</td>\n",
       "      <td>r,pharmacovigilance,clinical</td>\n",
       "      <td>Docs International UK Limited</td>\n",
       "      <td>M4 Corridor</td>\n",
       "      <td>UK</td>\n",
       "      <td>On Application</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c9de23d13d4dd71f917385947fe5b81</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Science</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Strategic Market Analyst</td>\n",
       "      <td>Hyper Recruitment Solutions are currently look...</td>\n",
       "      <td>210</td>\n",
       "      <td>r</td>\n",
       "      <td>Hyper Recruitment Solutions Ltd</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>UK</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             job_id post_date_parsed  \\\n",
       "0  15cc819a5d9a4b298bcc5fd839bd65a3       2018-04-14   \n",
       "1  31c1a5eac509952eeb8cfdccbeb2fcc4       2018-04-16   \n",
       "2  7b6abf608611f7c6b97be78b5914d26c       2018-04-16   \n",
       "3  63542ffb0393034e35a3f9753b274b73       2018-11-04   \n",
       "4  7c9de23d13d4dd71f917385947fe5b81       2018-04-13   \n",
       "\n",
       "                         category job_type_std  \\\n",
       "0               Clinical Research    Permanent   \n",
       "1                         Science    Permanent   \n",
       "2                         Science    Permanent   \n",
       "3  Data Management and Statistics    Permanent   \n",
       "4                         Science    Permanent   \n",
       "\n",
       "                                 job_title  \\\n",
       "0     Senior / Medical Writer (Regulatory)   \n",
       "1                    Manager of Biometrics   \n",
       "2  Field Service Engineer | Chromatography   \n",
       "3       Data Manager of Project Management   \n",
       "4                 Strategic Market Analyst   \n",
       "\n",
       "                               job_description_clean  desc_word_count  \\\n",
       "0  As part of our on-going growth, we are current...              359   \n",
       "1  Manager of Biometrics – Italy AL Solutions are...              291   \n",
       "2  A fantastic opportunity has arisen for an expe...              374   \n",
       "3  Job Details : Utilise extensive clinical data ...              279   \n",
       "4  Hyper Recruitment Solutions are currently look...              210   \n",
       "\n",
       "                    skill_flags                     company_name         city  \\\n",
       "0      r,biostatistics,clinical                   PPD GLOBAL LTD    Cambridge   \n",
       "1                sas,r,clinical                     AL Solutions         None   \n",
       "2                             r           Seltek Consultants Ltd         None   \n",
       "3  r,pharmacovigilance,clinical    Docs International UK Limited  M4 Corridor   \n",
       "4                             r  Hyper Recruitment Solutions Ltd    Cambridge   \n",
       "\n",
       "  country  salary_offered  salary_min  salary_max salary_currency  \\\n",
       "0      UK     Competitive         NaN         NaN             NaN   \n",
       "1  Europe            None         NaN         NaN             NaN   \n",
       "2      UK            None         NaN         NaN             NaN   \n",
       "3      UK  On Application         NaN         NaN             NaN   \n",
       "4      UK            None         NaN         NaN             NaN   \n",
       "\n",
       "   salary_parsed  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3644 entries, 0 to 30000\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   job_id                 3644 non-null   object        \n",
      " 1   post_date_parsed       3643 non-null   datetime64[ns]\n",
      " 2   category               3588 non-null   object        \n",
      " 3   job_type_std           3644 non-null   object        \n",
      " 4   job_title              3643 non-null   object        \n",
      " 5   job_description_clean  3644 non-null   object        \n",
      " 6   desc_word_count        3644 non-null   int64         \n",
      " 7   skill_flags            3643 non-null   object        \n",
      " 8   company_name           3643 non-null   object        \n",
      " 9   city                   1589 non-null   object        \n",
      " 10  country                3643 non-null   object        \n",
      " 11  salary_offered         2785 non-null   object        \n",
      " 12  salary_min             555 non-null    float64       \n",
      " 13  salary_max             555 non-null    float64       \n",
      " 14  salary_currency        295 non-null    object        \n",
      " 15  salary_parsed          3644 non-null   bool          \n",
      "dtypes: bool(1), datetime64[ns](1), float64(2), int64(1), object(11)\n",
      "memory usage: 459.1+ KB\n"
     ]
    }
   ],
   "source": [
    "display(df_clean.head(5))\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8b9b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_healthcare_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "clean_path = \"cleaned_healthcare_jobs.csv\"\n",
    "df_clean.to_csv(clean_path, index=False)\n",
    "print(f\"Cleaned data saved to {clean_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
